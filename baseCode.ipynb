{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890e31f1",
   "metadata": {},
   "source": [
    "### Intial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216dc56",
   "metadata": {},
   "source": [
    "Installation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852f1a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U autogen-agentchat autogen-ext[openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39d394",
   "metadata": {},
   "source": [
    "API key setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f48ea",
   "metadata": {},
   "source": [
    "### Multi Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4379d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import AssistantAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61131f8",
   "metadata": {},
   "source": [
    "Fine tuned Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41daaf",
   "metadata": {},
   "source": [
    "Semantic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trushatalati/micromamba/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Takes 30s to load the model \n",
    "from agents.semantic_agent.semantic_agent import SemanticAgent\n",
    "\n",
    "semantic_agent = SemanticAgent(\n",
    "    model_dir=\"agents/semantic_agent/t5_semantic_agent_final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f791244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.contrast_agent.contrast_agent import ContrastAgent\n",
    "\n",
    "contrast_agent = ContrastAgent(\n",
    "    model_dir=\"virajns2/contrast-violation-t5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the fine-tuned GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"path_to_model\") #TODO give path to model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"path_to_your_fine_tuned_model\")#TODO give path to tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21602c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import AssistantAgent\n",
    "\n",
    "class CustomGPT2Agent(AssistantAgent):\n",
    "    def __init__(self, name, model, tokenizer):\n",
    "        super().__init__(name=name)\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate_reply(self, messages):\n",
    "        # Extract the latest user message\n",
    "        user_message = messages[-1]['content']\n",
    "        \n",
    "        # Tokenize the input\n",
    "        inputs = self.tokenizer.encode(user_message, return_tensors='pt')\n",
    "        \n",
    "        # Generate a response\n",
    "        outputs = self.model.generate(inputs, max_length=150, num_return_sequences=1)\n",
    "        \n",
    "        # Decode the generated response\n",
    "        reply = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_agent = CustomGPT2Agent(name=\"CustomGPT2Agent\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f43bbc",
   "metadata": {},
   "source": [
    "GPT based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually Impaired Agent\n",
    "visually_impaired_agent = AssistantAgent(\n",
    "    name=\"VisuallyImpairedAgent\",\n",
    "    system_message=\"Simulate a user navigating via screen reader. Identify missing labels, improper heading structures, and ARIA attribute issues.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motor-Impaired Agent\n",
    "motor_impaired_agent = AssistantAgent(\n",
    "    name=\"MotorImpairedAgent\",\n",
    "    system_message=\"Simulate keyboard-only navigation. Detect elements not accessible via keyboard and lack of focus indicators.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color-Blind Agent\n",
    "color_blind_agent = AssistantAgent(\n",
    "    name=\"ColorBlindAgent\",\n",
    "    system_message=\"Analyze color usage for accessibility. Identify issues with color contrast and reliance on color cues.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04be84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_agent = AssistantAgent(\n",
    "    name=\"FixingAgent\",\n",
    "    system_message=\"Provide code-level fixes for identified accessibility issues based on best practices and guidelines, based on the problems stated by everyone\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48901926",
   "metadata": {},
   "source": [
    "Configure Agent Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b797de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    code_execution_config={\"use_docker\": False}\n",
    ")\n",
    "\n",
    "group_chat = GroupChat(\n",
    "    agents=[user_proxy, semantic_agent, contrast_agent, visually_impaired_agent, motor_impaired_agent, color_blind_agent, fixing_agent],\n",
    "    messages=[],\n",
    "    max_round=5\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(groupchat=group_chat, llm_config={\"model\": \"gpt-4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1291c",
   "metadata": {},
   "source": [
    "Run the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ecc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui = \"\" #TODO: FETCH RESPECTIVE DATA FROM TEST SET AND PASS TO SYSTEM\n",
    "\n",
    "user_proxy.initiate_chat(manager, message = ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e675f",
   "metadata": {},
   "source": [
    "Feed back loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f190135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in group_chat.messages:\n",
    "    if msg['role'] != 'FixingAgent':\n",
    "        fixing_agent.receive_message(msg)\n",
    "\n",
    "for msg in group_chat.messages:\n",
    "    print(f\"{msg['role']}: {msg['content']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
