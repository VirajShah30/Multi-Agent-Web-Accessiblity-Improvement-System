{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890e31f1",
   "metadata": {},
   "source": [
    "### Intial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216dc56",
   "metadata": {},
   "source": [
    "Installation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90852f1a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogen-agentchat\n",
      "  Downloading autogen_agentchat-0.5.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting autogen-ext[openai]\n",
      "  Downloading autogen_ext-0.5.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting autogen-core==0.5.6 (from autogen-agentchat)\n",
      "  Downloading autogen_core-0.5.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonref~=1.1.0 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting opentelemetry-api>=1.27.0 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pillow>=11.0.0 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting protobuf~=5.29.3 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pydantic<3.0.0,>=2.10.0 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "     ---------------------------------------- 0.0/66.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 66.6/66.6 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from autogen-core==0.5.6->autogen-agentchat) (4.11.0)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from autogen-ext[openai]) (22.1.0)\n",
      "Collecting openai>=1.66.5 (from autogen-ext[openai])\n",
      "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken>=0.8.0 (from autogen-ext[openai])\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.66.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.4.16)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.66.5->autogen-ext[openai]) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (0.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat) (7.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from autogen-core==0.5.6->autogen-agentchat)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.6->autogen-agentchat)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.66.5->autogen-ext[openai]) (0.4.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.6->autogen-agentchat) (3.18.1)\n",
      "Downloading autogen_agentchat-0.5.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.5/105.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading autogen_core-0.5.6-py3-none-any.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/94.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 94.7/94.7 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
      "   ---------------------------------------- 0.0/662.0 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 317.4/662.0 kB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 662.0/662.0 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   ---------------------------- ---------- 645.1/893.9 kB 13.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 893.9/893.9 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading autogen_ext-0.5.6-py3-none-any.whl (296 kB)\n",
      "   ---------------------------------------- 0.0/296.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 296.8/296.8 kB 17.9 MB/s eta 0:00:00\n",
      "Using cached jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.3/65.3 kB ? eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.6/2.7 MB 13.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.4/2.7 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.5/434.5 kB 26.5 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "   ---------------------------------------- 0.0/443.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 443.9/443.9 kB 27.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.0 MB 30.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/2.0 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 20.7 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, protobuf, pillow, jsonref, typing-inspection, tiktoken, pydantic-core, opentelemetry-api, pydantic, openai, autogen-core, autogen-ext, autogen-agentchat\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.3.0\n",
      "    Uninstalling pillow-10.3.0:\n",
      "      Successfully uninstalled pillow-10.3.0\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.1\n",
      "    Uninstalling pydantic_core-2.18.1:\n",
      "      Successfully uninstalled pydantic_core-2.18.1\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.24.0\n",
      "    Uninstalling opentelemetry-api-1.24.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.24.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.0\n",
      "    Uninstalling pydantic-2.7.0:\n",
      "      Successfully uninstalled pydantic-2.7.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.20.0\n",
      "    Uninstalling openai-1.20.0:\n",
      "      Successfully uninstalled openai-1.20.0\n",
      "Successfully installed autogen-agentchat-0.5.6 autogen-core-0.5.6 autogen-ext-0.5.6 jsonref-1.1.0 openai-1.77.0 opentelemetry-api-1.32.1 pillow-11.2.1 protobuf-5.29.4 pydantic-2.11.4 pydantic-core-2.33.2 tiktoken-0.9.0 typing-extensions-4.13.2 typing-inspection-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.11.4 which is incompatible.\n",
      "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "google-api-core 2.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\n",
      "langchain 0.3.3 requires langchain-core<0.4.0,>=0.3.10, but you have langchain-core 0.1.43 which is incompatible.\n",
      "langchain-community 0.3.2 requires langchain-core<0.4.0,>=0.3.10, but you have langchain-core 0.1.43 which is incompatible.\n",
      "langchain-community 0.3.2 requires langsmith<0.2.0,>=0.1.125, but you have langsmith 0.1.48 which is incompatible.\n",
      "langchain-community 0.3.2 requires pydantic-settings<3.0.0,>=2.4.0, but you have pydantic-settings 2.2.1 which is incompatible.\n",
      "langchain-huggingface 0.1.0 requires huggingface-hub>=0.23.0, but you have huggingface-hub 0.22.2 which is incompatible.\n",
      "langchain-huggingface 0.1.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.1.43 which is incompatible.\n",
      "langchain-huggingface 0.1.0 requires tokenizers>=0.19.1, but you have tokenizers 0.15.2 which is incompatible.\n",
      "langchain-openai 0.2.2 requires langchain-core<0.4.0,>=0.3.9, but you have langchain-core 0.1.43 which is incompatible.\n",
      "langchain-text-splitters 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.1.43 which is incompatible.\n",
      "opentelemetry-proto 1.24.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.29.4 which is incompatible.\n",
      "opentelemetry-sdk 1.24.0 requires opentelemetry-api==1.24.0, but you have opentelemetry-api 1.32.1 which is incompatible.\n",
      "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.29.4 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\n",
      "torchaudio 2.2.2 requires torch==2.2.2, but you have torch 2.2.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\viraj\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\viraj\\anaconda3\\lib\\site-packages (4.39.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\viraj\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/991.5 kB 991.0 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 532.5/991.5 kB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U autogen-agentchat autogen-ext[openai]\n",
    "!pip install torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39d394",
   "metadata": {},
   "source": [
    "API key setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f48ea",
   "metadata": {},
   "source": [
    "### Multi Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4379d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import AssistantAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61131f8",
   "metadata": {},
   "source": [
    "#### Fine tuned Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffbb65",
   "metadata": {},
   "source": [
    "wrapper agent for autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9357aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import AssistantAgent\n",
    "\n",
    "class LocalModelWrapperAgent(AssistantAgent):\n",
    "    def __init__(self, name: str, model_agent):\n",
    "        super().__init__(name=name)\n",
    "        self.model_agent = model_agent\n",
    "\n",
    "    def generate_reply(self, messages, sender=None, **kwargs):\n",
    "        # Safe wrapper with fallback\n",
    "        try:\n",
    "            raw_json = messages[0][\"content\"]  # Expecting first message to be UI JSON\n",
    "            reply = self.model_agent.handle(raw_json)\n",
    "            return reply\n",
    "        except Exception as e:\n",
    "            return f\"[{self.name}] Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41daaf",
   "metadata": {},
   "source": [
    "Semantic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "195e30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from agents.semantic_agent.agent import SemanticAgent\n",
    "\n",
    "semantic_model = SemanticAgent(model_dir=\"trusha88/t5-semantic-agent\")\n",
    "semantic_agent = LocalModelWrapperAgent(name=\"semantic-agent\", model_agent=semantic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b07cf",
   "metadata": {},
   "source": [
    "Contrast Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f791244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from agents.contrast_agent.agent import ContrastAgent\n",
    "\n",
    "contrast_model = ContrastAgent(model_dir=\"virajns2/contrast-violation-t5\")\n",
    "contrast_agent = LocalModelWrapperAgent(name=\"contrast-agent\", model_agent=contrast_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f43bbc",
   "metadata": {},
   "source": [
    "### GPT based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f0a6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually Impaired Agent\n",
    "visually_impaired_agent = AssistantAgent(\n",
    "    name=\"VisuallyImpairedAgent\",\n",
    "    system_message=\"Simulate a user navigating via screen reader. Identify missing labels, improper heading structures, and ARIA attribute issues.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c0022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motor-Impaired Agent\n",
    "motor_impaired_agent = AssistantAgent(\n",
    "    name=\"MotorImpairedAgent\",\n",
    "    system_message=\"Simulate keyboard-only navigation. Detect elements not accessible via keyboard and lack of focus indicators.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae86cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color-Blind Agent\n",
    "color_blind_agent = AssistantAgent(\n",
    "    name=\"ColorBlindAgent\",\n",
    "    system_message=\"Analyze color usage for accessibility. Identify issues with color contrast and reliance on color cues.\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c04be84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_agent = AssistantAgent(\n",
    "    name=\"FixingAgent\",\n",
    "    system_message=\"Provide code-level fixes for identified accessibility issues based on best practices and guidelines, based on the problems stated by everyone\",\n",
    "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48901926",
   "metadata": {},
   "source": [
    "Configure Agent Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b797de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    code_execution_config={\"use_docker\": False}\n",
    ")\n",
    "\n",
    "group_chat = GroupChat(\n",
    "    agents=[user_proxy, semantic_agent, contrast_agent, visually_impaired_agent, motor_impaired_agent, color_blind_agent, fixing_agent],\n",
    "    messages=[],\n",
    "    max_round=5\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(groupchat=group_chat, llm_config={\"model\": \"gpt-4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1291c",
   "metadata": {},
   "source": [
    "Run the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a05ecc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: FETCH RESPECTIVE DATA FROM TEST SET AND PASS TO SYSTEM\n",
    "with open(\"test_data/test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ui = f.read()\n",
    "ui = \"role: link, fg: 120,120,120, bg: 255,255,255, contrast: 2.9\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e675f",
   "metadata": {},
   "source": [
    "Feed back loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa23e92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The link element has a foreground color of RGB(120,120,120) and background color of RGB(255,255,255) resulting in a contrast ratio of 2.9. This is below the WCAG recommended minimum of 4.5:1 for normal text.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_agent.model_agent.handle(ui) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c445c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# Step 1: Define agents (you already did this)\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    code_execution_config={\"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Step 2: Set up group chat (we'll use this for message context)\n",
    "group_chat = GroupChat(\n",
    "    agents=[user_proxy, semantic_agent, contrast_agent, visually_impaired_agent, motor_impaired_agent, color_blind_agent, fixing_agent],\n",
    "    messages=[],\n",
    "    max_round=5\n",
    ")\n",
    "manager = GroupChatManager(groupchat=group_chat, llm_config={\"model\": \"gpt-4\"})\n",
    "\n",
    "# Step 3: Load JSON\n",
    "with open(\"test_data/test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ui = f.read()\n",
    "\n",
    "    \n",
    "ui = \"role: link, fg: 120,120,120, bg: 255,255,255, contrast: 2.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28a80dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contrast-agent]: The link element has a foreground color of RGB(120,120,120) and background color of RGB(255,255,255) resulting in a contrast ratio of 2.9. This is below the WCAG recommended minimum of 4.5:1 for normal text.\n",
      "\n",
      "[VisuallyImpairedAgent]: [screen-reader]\n",
      "\"Unlabeled link.\"\n",
      "\n",
      "[accessibility-issue]\n",
      "The link element is missing a descriptive label or text. This makes it difficult for screen reader users to understand the purpose of the link.\n",
      "\n",
      "[MotorImpairedAgent]: [KeyboardNavigationAgent]\n",
      "[tab]\n",
      "\"Link.\"\n",
      "\n",
      "[accessibility-issue]\n",
      "The link element is accessible via keyboard navigation. However, there is no visible focus indicator when the link is selected. This makes it difficult for keyboard-only users to track their navigation.\n",
      "\n",
      "[ColorBlindAgent]: [ColorBlindAgent]\n",
      "[ColorContrastAgent]\n",
      "The link element has a foreground color of RGB(120,120,120) and a background color of RGB(255,255,255). This results in a contrast ratio of 2.9, which is below the minimum recommended contrast ratio of 4.5:1 for normal text. This may make the text difficult to read for users with color vision deficiencies. \n",
      "\n",
      "[accessibility-issue]\n",
      "The link element relies solely on color to convey its function. This can be problematic for users with color vision deficiencies who may not be able to distinguish the link from the surrounding text. Consider adding an underline or other non-color cue to indicate that the text is a link.\n",
      "\n",
      "[FixingAgent]: [contrast-agent]\n",
      "To fix the contrast issue, you can adjust the foreground color to a darker shade. Here's an example:\n",
      "\n",
      "```css\n",
      "a {\n",
      "  color: #595959; /* RGB(89,89,89) */\n",
      "  background-color: #FFFFFF; /* RGB(255,255,255) */\n",
      "}\n",
      "```\n",
      "This will give you a contrast ratio of approximately 4.54:1, which meets the WCAG AA standard for normal text.\n",
      "\n",
      "[VisuallyImpairedAgent]\n",
      "To fix the issue with the missing descriptive label, you can add an \"aria-label\" attribute to the link element. Here's an example:\n",
      "\n",
      "```html\n",
      "<a href=\"https://example.com\" aria-label=\"Example Link\">Click here</a>\n",
      "```\n",
      "\n",
      "[MotorImpairedAgent]\n",
      "To fix the issue with the missing focus indicator, you can add a CSS rule to provide a visible outline when the link is focused. Here's an example:\n",
      "\n",
      "```css\n",
      "a:focus {\n",
      "  outline: 2px solid #000000; /* Change as needed */\n",
      "}\n",
      "```\n",
      "\n",
      "[ColorBlindAgent]\n",
      "To fix the issue with the link relying solely on color, you can add an underline to the link. Here's an example:\n",
      "\n",
      "```css\n",
      "a {\n",
      "  text-decoration: underline;\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load test input\n",
    "# with open(\"test_data/test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     ui = f.read()\n",
    "\n",
    "# Step 2: Reset group chat with initial user input\n",
    "group_chat.messages = [{\"role\": \"user\", \"content\": ui}]\n",
    "\n",
    "# Step 3: Manually invoke each accessibility agent\n",
    "ordered_agents = [\n",
    "    # semantic_agent,  # include this if you want\n",
    "    contrast_agent,\n",
    "    visually_impaired_agent,\n",
    "    motor_impaired_agent,\n",
    "    color_blind_agent,\n",
    "]\n",
    "\n",
    "for agent in ordered_agents:\n",
    "    try:\n",
    "        reply = agent.generate_reply(group_chat.messages)\n",
    "\n",
    "        # ✅ Append with valid OpenAI role and embed agent name in content\n",
    "        group_chat.messages.append({\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": f\"[{agent.name}]\\n{reply}\"\n",
    "        })\n",
    "\n",
    "        print(f\"[{agent.name}]: {reply}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in {agent.name}: {e}\")\n",
    "\n",
    "# Step 4: Fixing agent responds last\n",
    "try:\n",
    "    final_reply = fixing_agent.generate_reply(group_chat.messages)\n",
    "    group_chat.messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"[{fixing_agent.name}]\\n{final_reply}\"\n",
    "    })\n",
    "    print(f\"[{fixing_agent.name}]: {final_reply}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in FixingAgent: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f24099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
