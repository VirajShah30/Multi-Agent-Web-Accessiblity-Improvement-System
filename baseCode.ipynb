{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6216dc56",
      "metadata": {
        "id": "6216dc56"
      },
      "source": [
        "### Installation of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90852f1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90852f1a",
        "outputId": "67260530-fb37-475a-820a-87b31e3e282c",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -U autogen-agentchat autogen-ext[openai]\n",
        "!pip install torch transformers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76zMqb7x9-Ve",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76zMqb7x9-Ve",
        "outputId": "98754e65-e201-4e92-8156-7284b010e45d"
      },
      "outputs": [],
      "source": [
        "!pip install autogen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890e31f1",
      "metadata": {
        "id": "890e31f1"
      },
      "source": [
        "### Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf39d394",
      "metadata": {
        "id": "cf39d394"
      },
      "source": [
        "API key setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "babfaba2",
      "metadata": {
        "id": "babfaba2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y0a1bhpU-I2z",
      "metadata": {
        "id": "y0a1bhpU-I2z"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HpF_1bsJ-IYR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpF_1bsJ-IYR",
        "outputId": "23badc48-4757-47b2-db37-cd1e943ad27a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMaPjdK2-Bzv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMaPjdK2-Bzv",
        "outputId": "76ae0b15-391b-4cd7-c0c7-f903322925f5"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/WebUI-7k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59f48ea",
      "metadata": {
        "id": "b59f48ea"
      },
      "source": [
        "### Multi Agent Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61131f8",
      "metadata": {
        "id": "a61131f8"
      },
      "source": [
        "#### Fine tuned Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cffbb65",
      "metadata": {
        "id": "6cffbb65"
      },
      "source": [
        "Wrapper agent for autogen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd41daaf",
      "metadata": {
        "id": "dd41daaf"
      },
      "source": [
        "Semantic, Contrast Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195e30bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "195e30bf",
        "outputId": "63993281-2325-4a3c-b7b7-1f5ca2b8d8f0"
      },
      "outputs": [],
      "source": [
        "from agents.semantic_agent.agent import SemanticAgent\n",
        "from agents.contrast_agent.agent import ContrastAgent\n",
        "from agents.image_captioning_agent.agent import ImageCaptioningAgent\n",
        "\n",
        "semantic_model = SemanticAgent(model_dir=\"trusha88/t5-semantic-agent\")\n",
        "contrast_model = ContrastAgent(model_dir=\"virajns2/contrast-violation-t5\")\n",
        "image_caption_model = ImageCaptioningAgent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "H7y7vT0vscw-",
      "metadata": {
        "id": "H7y7vT0vscw-"
      },
      "outputs": [],
      "source": [
        "from agents.axe_violations_agent.agent import AxeViolationsAgent\n",
        "\n",
        "axe_agent = AxeViolationsAgent()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f43bbc",
      "metadata": {
        "id": "72f43bbc"
      },
      "source": [
        "#### GPT based Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "hOr_CAoavFt8",
      "metadata": {
        "id": "hOr_CAoavFt8"
      },
      "outputs": [],
      "source": [
        "from autogen import AssistantAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2f0a6414",
      "metadata": {
        "id": "2f0a6414"
      },
      "outputs": [],
      "source": [
        "# Visually Impaired Agent\n",
        "visually_impaired_agent = AssistantAgent(\n",
        "    name=\"VisuallyImpairedAgent\",\n",
        "    system_message=\"You are a screen‑reader user. Given the following combined accessibility summary from the SemanticAgent and ContrastAgent, analyze it and respond with any additional issues or validations as you navigate the page. Include explicit references to each semantic and contrast finding.\",\n",
        "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "08c0022f",
      "metadata": {
        "id": "08c0022f"
      },
      "outputs": [],
      "source": [
        "# Motor-Impaired Agent\n",
        "motor_impaired_agent = AssistantAgent(\n",
        "    name=\"MotorImpairedAgent\",\n",
        "    system_message=\"You are a keyboard‑only user. Given the combined accessibility summary above, walk through the page structure and identify keyboard navigation barriers (e.g., tabindex issues, missing focus styles). Refer back to each semantic/contrast point in your response.\",\n",
        "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ae86cf6f",
      "metadata": {
        "id": "ae86cf6f"
      },
      "outputs": [],
      "source": [
        "# Color-Blind Agent\n",
        "color_blind_agent = AssistantAgent(\n",
        "    name=\"ColorBlindAgent\",\n",
        "    system_message=\"You are a color‑blind user. Using the combined summary, assess whether the listed contrast ratios and semantic issues affect your ability to distinguish page elements. Call out any color‑related problems or confirm that the reported contrast ratio is sufficient.\",\n",
        "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c04be84f",
      "metadata": {
        "id": "c04be84f"
      },
      "outputs": [],
      "source": [
        "fixing_agent = AssistantAgent(\n",
        "    name=\"FixingAgent\",\n",
        "    system_message=\"You are the final‑stage accessibility engineer. Given the full conversation history—including the semantic and contrast summaries and each simulation agent’s findings—produce a consolidated list of code‑level fixes. For each issue, reference which agent(s) raised it, then provide the minimal HTML/CSS/ARIA snippet needed to resolve it.\",\n",
        "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48901926",
      "metadata": {
        "id": "48901926"
      },
      "source": [
        "### Configure Agent Interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f24099",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9f24099",
        "outputId": "1a7e8d82-1c82-49d9-a230-bb64b1391313"
      },
      "outputs": [],
      "source": [
        "from autogen.agentchat import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
        "import json\n",
        "\n",
        "# A silent proxy for driving “human” turns\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"UserProxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=1,\n",
        "    code_execution_config={\"use_docker\": False}\n",
        ")\n",
        "\n",
        "# Load your UI JSON once\n",
        "with open(\"test_data/test_file.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    ui_json = json.load(f)\n",
        "\n",
        "# Make sure ui_str is a JSON string:\n",
        "if isinstance(ui_json, dict):\n",
        "    ui_str = json.dumps(ui_json)\n",
        "else:\n",
        "    ui_str = ui_json\n",
        "\n",
        "print(json.dumps(ui_json, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hu9e4qQRUlXM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu9e4qQRUlXM",
        "outputId": "29f4545e-9e3d-4614-ed6f-60a7f7e67a77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 1) Make sure your JSON is a string\n",
        "if isinstance(ui_json, dict):\n",
        "    ui_str = json.dumps(ui_json)\n",
        "else:\n",
        "    ui_str = ui_json\n",
        "\n",
        "# 2) Wrap your T5 agents exactly as before\n",
        "class ChatWrapperAgent(AssistantAgent):\n",
        "    def __init__(self, name: str, t5_agent):\n",
        "        super().__init__(name=name)\n",
        "        self.t5_agent = t5_agent\n",
        "\n",
        "    def generate_reply(self, messages, sender=None, **kwargs):\n",
        "        # take the content of the *first* message as raw JSON\n",
        "        raw_json = messages[0][\"content\"]\n",
        "        return self.t5_agent.handle(raw_json)\n",
        "\n",
        "semantic_wrapper = ChatWrapperAgent(\"semantic-agent\", semantic_model)\n",
        "contrast_wrapper = ChatWrapperAgent(\"contrast-agent\", contrast_model)\n",
        "axe_wrapper = ChatWrapperAgent(\"axe-violations-agent\", axe_agent)\n",
        "image_captioning_wrapper = ChatWrapperAgent(\"image-captioning-agent\", image_caption_model)\n",
        "\n",
        "# 3) Manually invoke them on the same single‐element history:\n",
        "history = [{\"role\": \"user\", \"content\": ui_str}]\n",
        "\n",
        "semantic_summary  = semantic_wrapper.generate_reply(history)\n",
        "contrast_summary = contrast_wrapper.generate_reply(history)\n",
        "axe_violations_summary = axe_wrapper.generate_reply(history)\n",
        "image_captioning_summary = image_captioning_wrapper.generate_reply(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h3eWWJd3XMim",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3eWWJd3XMim",
        "outputId": "034fd881-0193-4a80-955d-260abc6ee44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Combined Summary ===\n",
            "SemanticAgent: On page 1656130839224 (viewport 1920-1080) we detected the following semantic violations: Violation 1 — **landmark-one-main** (impact: moderate) • Description: Ensures the document has a main landmark. • Recommendation: Document must have one main landmark. See https://dequeuniversity.com/rules/axe/3.5/landmark-one-main?application=axe-puppeteer • Detail: Element \"h4>\" at html failed: Document does not have a main landmark. Violation 2 — **page-has-heading-one** (impact: moderate) • Description: Ensure that the page, or at least one of its frames contains a level-one heading. • Recommendation: Page must contain a level-one heading. See https://dequeuniversity.com/rules/axe/3.5/page-has-heading-one?application=axe-puppeteer • Detail: Element \"html>\" at html failed: Page must have a level\n",
            "\n",
            "ContrastAgent: The link element has a foreground color of RGB(255,255,255) and background color of RGB(52,58,64) resulting in a contrast ratio of 11.51.\n",
            "\n",
            "AxeViolationsAgent: - bypass (impact: serious)\n",
            "    Categories: cat.keyboard\n",
            "    Description: Ensures each page has at least one mechanism for a user to bypass navigation and jump straight to the content\n",
            "    Help: Page must have means to bypass repeated blocks\n",
            "    FailureSummary: Fix any of the following:; No valid skip link found; Page does not have a heading; Page does not have a landmark region\n",
            "- html-has-lang (impact: serious)\n",
            "    Categories: cat.language\n",
            "    Description: Ensures every HTML document has a lang attribute\n",
            "    Help: <html> element must have a lang attribute\n",
            "    FailureSummary: Fix any of the following:; The <html> element does not have a lang attribute\n",
            "- image-alt (impact: critical)\n",
            "    Categories: cat.text-alternatives\n",
            "    Description: Ensures <img> elements have alternate text or a role of none or presentation\n",
            "    Help: Images must have alternate text\n",
            "    FailureSummary: Fix any of the following:; Element does not have an alt attribute; aria-label attribute does not exist or is empty; aria-labelledby attribute does not exist, references elements that do not exist or references elements that are empty; Element has no title attribute or the title attribute is empty; Element's default semantics were not overridden with role=\"presentation\"; Element's default semantics were not overridden with role=\"none\"\n",
            "- landmark-one-main (impact: moderate)\n",
            "    Categories: cat.semantics\n",
            "    Description: Ensures the document has a main landmark\n",
            "    Help: Document must have one main landmark\n",
            "    FailureSummary: Fix all of the following:; Document does not have a main landmark\n",
            "- page-has-heading-one (impact: moderate)\n",
            "    Categories: cat.semantics\n",
            "    Description: Ensure that the page, or at least one of its frames contains a level-one heading\n",
            "    Help: Page must contain a level-one heading\n",
            "    FailureSummary: Fix all of the following:; Page must have a level-one heading\n",
            "- region (impact: moderate)\n",
            "    Categories: cat.keyboard\n",
            "    Description: Ensures all page content is contained by landmarks\n",
            "    Help: All page content must be contained by landmarks\n",
            "    FailureSummary: Fix any of the following:; Some page content is not contained by landmarks\n"
          ]
        }
      ],
      "source": [
        "combined_summary = (\n",
        "    f\"SemanticAgent: {semantic_summary}\\n\\n\"\n",
        "    f\"ContrastAgent: {contrast_summary}\\n\\n\"\n",
        "    f\"AxeViolationsAgent: {axe_violations_summary}\\n\\n\"\n",
        "    f\"ImageCaptioningAgent: {image_captioning_summary}\\n\\n\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== Combined Summary ===\")\n",
        "print(combined_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MOXMP0__UlVG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MOXMP0__UlVG",
        "outputId": "8af0188f-3aa0-4a21-fa54-5ade83d15c95"
      },
      "outputs": [],
      "source": [
        "from autogen.agentchat import UserProxyAgent, GroupChat, GroupChatManager\n",
        "\n",
        "# 1) Rebuild the echo agents around your summaries\n",
        "class EchoAgent(AssistantAgent):\n",
        "    def __init__(self, name: str, summary: str):\n",
        "        super().__init__(name=name)\n",
        "        self.summary = summary\n",
        "\n",
        "    def generate_reply(self, messages=None, sender=None, **kwargs):\n",
        "        return self.summary\n",
        "\n",
        "echo_semantic = EchoAgent(\"semantic-agent\", semantic_summary)\n",
        "echo_contrast = EchoAgent(\"contrast-agent\", contrast_summary)\n",
        "echo_axe_violations = EchoAgent(\"axe-violations-agent\", axe_violations_summary)\n",
        "echo_image_captioning = EchoAgent(\"image-captioning-agent\", image_captioning_summary)\n",
        "\n",
        "# 2) Configure your proxy\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"UserProxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=1,\n",
        "    code_execution_config={\"use_docker\": False}\n",
        ")\n",
        "\n",
        "# 3) Build the GroupChat with explicit round‑robin ordering\n",
        "group_chat = GroupChat(\n",
        "    agents=[\n",
        "        user_proxy,\n",
        "        echo_semantic,\n",
        "        echo_contrast,\n",
        "        echo_axe_violations,\n",
        "        echo_image_captioning,\n",
        "        visually_impaired_agent,\n",
        "        motor_impaired_agent,\n",
        "        color_blind_agent,\n",
        "        fixing_agent\n",
        "    ],\n",
        "    messages=[],  # no pre‑seed\n",
        "    max_round=8,\n",
        "    speaker_selection_method=\"round_robin\",\n",
        "    allow_repeat_speaker=False\n",
        ")\n",
        "\n",
        "# 4) Bind a new manager\n",
        "manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config={\"model\": \"gpt-4\", \"temperature\": 0}\n",
        ")\n",
        "\n",
        "# 5) Kick off with your combined summary; max_turns = 6 agents after the proxy\n",
        "chat_result = user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=combined_summary,\n",
        "    clear_history=True,\n",
        "    max_turns=1\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6216dc56",
        "890e31f1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
